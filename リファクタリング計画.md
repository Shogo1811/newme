# リファクタリング計画

## 1. 問題点の概要

コードレビューの結果、以下の主要な問題点が特定されました。

### 重要度：高
1. **グローバル変数の使用** (app.py)
2. **エラーハンドリングの欠如**
3. **セキュリティ上の問題**（ファイルアップロード検証なし）
4. **process_and_predict関数の肥大化** (model_utils.py:64-167)

### 重要度：中
5. **データの重複読み込み** (model_utils.py:128)
6. **マジックナンバーの多用**
7. **設定値のハードコーディング**

### 重要度：低
8. **テストコードの不在**
9. **ロギングの不足**
10. **型ヒントの不統一**

---

## 2. 詳細な問題分析

### 2.1 グローバル変数の使用（重要度：高）

#### 問題箇所: app.py:6-11, 19
```python
# グローバル変数（予測結果保存用）
rmse = None
r2 = None
plot_path = None
predictions_by_ward = None
actual_prices_by_ward = None
era_predictions = None

@app.route("/", methods=["GET", "POST"])
def upload_file():
    global rmse, r2, plot_path, predictions_by_ward, actual_prices_by_ward, era_predictions
```

#### 問題点
- スレッドセーフでない
- 複数ユーザー同時使用時にデータ競合が発生
- テストが困難
- コードの可読性・保守性が低い

#### 影響範囲
- 全てのルート関数 (app.py:17-66)

#### 解決策
**オプション1: Flaskセッションの使用**
```python
from flask import session

app.secret_key = 'your-secret-key-here'

@app.route("/", methods=["GET", "POST"])
def upload_file():
    if request.method == "POST":
        # 処理
        session['rmse'] = rmse
        session['r2'] = r2
        # ...
```

**オプション2: データクラスによる管理**
```python
from dataclasses import dataclass
from typing import Optional, Dict

@dataclass
class PredictionResult:
    rmse: float
    r2: float
    plot_path: str
    predictions_by_ward: Dict[str, int]
    actual_prices_by_ward: Dict[str, int]
    era_predictions: Dict[str, Dict[str, int]]

# Flaskセッションまたはデータベースで管理
```

---

### 2.2 エラーハンドリングの欠如（重要度：高）

#### 問題箇所: app.py:20-31
```python
if request.method == "POST":
    file = request.files.get("file")
    if file:  # ← ファイル名が空の場合の処理なし
        os.makedirs("input", exist_ok=True)
        filepath = os.path.join("input", file.filename)
        file.save(filepath)  # ← エラー時の処理なし

        # CSVを使って予測を実行
        rmse, r2, ... = process_and_predict(filepath)  # ← 例外処理なし
```

#### 問題点
- ファイルが選択されていない場合の処理なし
- CSV読み込みエラー時の処理なし
- 予測処理失敗時のフォールバック処理なし
- ユーザーへのエラーメッセージ表示なし

#### 解決策
```python
from flask import flash

@app.route("/", methods=["GET", "POST"])
def upload_file():
    if request.method == "POST":
        file = request.files.get("file")

        # バリデーション
        if not file or file.filename == "":
            flash("ファイルが選択されていません", "error")
            return redirect(url_for("upload_file"))

        if not allowed_file(file.filename):
            flash("CSVファイルのみアップロード可能です", "error")
            return redirect(url_for("upload_file"))

        try:
            # ファイル保存
            filename = secure_filename(file.filename)
            filepath = os.path.join("input", filename)
            file.save(filepath)

            # 予測実行
            result = process_and_predict(filepath)
            session['prediction_result'] = result
            return redirect(url_for("result_overview"))

        except KeyError as e:
            flash(f"CSVファイルの形式が不正です: {e}", "error")
            return redirect(url_for("upload_file"))
        except ValueError as e:
            flash(f"データの処理中にエラーが発生しました: {e}", "error")
            return redirect(url_for("upload_file"))
        except Exception as e:
            flash(f"予期しないエラーが発生しました: {e}", "error")
            return redirect(url_for("upload_file"))

    return render_template("upload.html")
```

---

### 2.3 セキュリティ上の問題（重要度：高）

#### 問題箇所: app.py:22-25
```python
if file:
    os.makedirs("input", exist_ok=True)
    filepath = os.path.join("input", file.filename)  # ← ファイル名検証なし
    file.save(filepath)
```

#### 問題点
1. **ファイル名のサニタイズなし**
   - パストラバーサル攻撃のリスク
   - 例: `../../etc/passwd` のようなファイル名
2. **ファイル形式の検証なし**
   - 任意のファイルをアップロード可能
3. **ファイルサイズ制限なし**
   - DoS攻撃のリスク
4. **CSRF対策なし**
   - クロスサイトリクエストフォージェリのリスク

#### 解決策
```python
from werkzeug.utils import secure_filename
from flask_wtf.csrf import CSRFProtect

# 設定
ALLOWED_EXTENSIONS = {'csv'}
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB

app.config['MAX_CONTENT_LENGTH'] = MAX_FILE_SIZE
csrf = CSRFProtect(app)

def allowed_file(filename):
    """ファイル拡張子の検証"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route("/", methods=["GET", "POST"])
def upload_file():
    if request.method == "POST":
        file = request.files.get("file")

        if not file or file.filename == "":
            flash("ファイルが選択されていません", "error")
            return redirect(url_for("upload_file"))

        if not allowed_file(file.filename):
            flash("CSVファイルのみアップロード可能です", "error")
            return redirect(url_for("upload_file"))

        # ファイル名のサニタイズ
        filename = secure_filename(file.filename)
        filepath = os.path.join("input", filename)

        try:
            file.save(filepath)
            # 処理続行
        except Exception as e:
            flash(f"ファイル保存に失敗しました: {e}", "error")
            return redirect(url_for("upload_file"))
```

---

### 2.4 process_and_predict関数の肥大化（重要度：高）

#### 問題箇所: model_utils.py:64-167
```python
def process_and_predict(file_path: str, plot_path: str = "static/result.png"):
    # 104行の巨大関数
    # - フォント設定
    # - CSV読み込み
    # - データ前処理
    # - モデル学習
    # - 散布図生成
    # - 区ごと集計
    # - 築年帯集計
    # - 年次推移グラフ生成
```

#### 問題点
- 単一責任の原則違反（1関数が8つの責務を持つ）
- テストが困難
- 再利用性が低い
- コードの可読性が低い
- 修正時のリスクが高い

#### 解決策：関数分割
```python
# 1. データ読み込み・前処理
def load_and_preprocess_data(file_path: str) -> pd.DataFrame:
    """CSVファイルを読み込み、前処理を行う"""
    pass

# 2. 特徴量エンジニアリング
def create_features(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:
    """特徴量を作成し、X, yを返す"""
    pass

# 3. モデル学習・評価
def train_and_evaluate_model(X, y) -> tuple[RandomForestRegressor, float, float, np.ndarray, np.ndarray]:
    """モデルを学習し、評価指標と予測値を返す"""
    pass

# 4. グラフ生成
def create_scatter_plot(y_test, y_pred, save_path: str):
    """散布図を生成・保存"""
    pass

def create_yearly_trend_plot(df: pd.DataFrame, save_path: str):
    """年次推移グラフを生成・保存"""
    pass

# 5. 集計処理
def aggregate_by_ward(df: pd.DataFrame, predictions: np.ndarray) -> tuple[dict, dict]:
    """区ごとの予測・実価格を集計"""
    pass

def aggregate_by_era(df: pd.DataFrame, predictions: np.ndarray) -> dict:
    """築年帯ごとの予測価格を集計"""
    pass

# メイン関数（オーケストレーション）
def process_and_predict(file_path: str, plot_path: str = "static/result.png"):
    """予測処理のメイン関数"""
    setup_japanese_font()

    df = load_and_preprocess_data(file_path)
    X, y = create_features(df)
    model, rmse, r2, y_test, y_pred = train_and_evaluate_model(X, y)

    create_scatter_plot(y_test, y_pred, plot_path)

    predictions_by_ward, actuals_by_ward = aggregate_by_ward(df, model.predict(X))
    era_predictions = aggregate_by_era(df, model.predict(X))

    create_yearly_trend_plot(df, "static/yearly_trend.png")

    return rmse, r2, plot_path, predictions_by_ward, actuals_by_ward, era_predictions
```

---

### 2.5 データの重複読み込み（重要度：中）

#### 問題箇所: model_utils.py:68, 128
```python
# 1回目: 前処理用
df = pd.read_csv(file_path, encoding="cp932")  # 68行目
# ... 処理 ...

# 2回目: 元データ取得用
original_df = pd.read_csv(file_path, encoding="cp932")  # 128行目
```

#### 問題点
- 同じファイルを2回読み込み（パフォーマンス低下）
- メモリ使用量の増加
- I/O処理の無駄

#### 解決策
```python
def process_and_predict(file_path: str, plot_path: str = "static/result.png"):
    setup_japanese_font()

    # 1回だけ読み込み、元データをコピー保持
    df_original = pd.read_csv(file_path, encoding="cp932")
    df_original.columns = df_original.columns.str.replace("\ufeff", "")

    # 処理用にコピーを作成
    df = df_original.copy()

    # 以降、df_originalは元データとして保持
    # dfは前処理用として使用
```

---

### 2.6 マジックナンバーの多用（重要度：中）

#### 問題箇所: model_utils.py
```python
# 79行目: 築年の基準年
df["築年帯"] = pd.cut(2025 - df["建築年"], ...)

# 102行目: 価格フィルタ閾値
filtered = comparison[(comparison["Actual Price"] < 250000000) & ...]

# 106-107行目: グラフの軸範囲
ticks = np.arange(0, 2.1e8, 5e7)
ax.set_xlim(0, 2e8)

# 139行目: 築年の基準年（重複）
2025 - original_df["建築年"]
```

#### 問題点
- 意味が不明瞭
- 変更時に複数箇所を修正する必要がある
- 保守性が低い

#### 解決策
```python
# 定数定義（ファイル冒頭またはconfig.py）
CURRENT_YEAR = 2025
PRICE_FILTER_THRESHOLD = 250_000_000  # 2.5億円
GRAPH_MAX_PRICE = 200_000_000  # 2億円
GRAPH_TICK_INTERVAL = 50_000_000  # 5千万円
AGE_BINS = [0, 10, 20, 999]
AGE_LABELS = ["築10年未満", "築10～20年", "築20年以上"]

# 使用例
df["築年帯"] = pd.cut(
    CURRENT_YEAR - df["建築年"],
    bins=AGE_BINS,
    labels=AGE_LABELS
)

filtered = comparison[
    (comparison["Actual Price"] < PRICE_FILTER_THRESHOLD) &
    (comparison["Predicted Price"] < PRICE_FILTER_THRESHOLD)
]
```

---

### 2.7 設定値のハードコーディング（重要度：中）

#### 問題箇所
```python
# app.py:70
app.run(debug=True, port=5002)

# model_utils.py:68
df = pd.read_csv(file_path, encoding="cp932")

# model_utils.py:91
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# model_utils.py:93
model = RandomForestRegressor(random_state=42)
```

#### 問題点
- 環境ごとの設定変更が困難
- 本番環境でdebug=Trueのまま実行される危険性
- ハイパーパラメータのチューニングが困難

#### 解決策：設定ファイルの作成
```python
# config.py
import os
from dataclasses import dataclass

@dataclass
class Config:
    # Flask設定
    SECRET_KEY: str = os.environ.get('SECRET_KEY', 'dev-secret-key')
    DEBUG: bool = os.environ.get('FLASK_DEBUG', 'False') == 'True'
    PORT: int = int(os.environ.get('PORT', 5002))

    # ファイル設定
    UPLOAD_FOLDER: str = 'input'
    STATIC_FOLDER: str = 'static'
    MAX_FILE_SIZE: int = 50 * 1024 * 1024  # 50MB
    ALLOWED_EXTENSIONS: set = {'csv'}
    CSV_ENCODING: str = 'cp932'

    # 機械学習設定
    TEST_SIZE: float = 0.2
    RANDOM_STATE: int = 42
    RF_N_ESTIMATORS: int = 100
    RF_MAX_DEPTH: int = None
    RF_N_JOBS: int = -1

    # グラフ設定
    PLOT_DPI: int = 300
    SCATTER_PLOT_PATH: str = 'static/result.png'
    TREND_PLOT_PATH: str = 'static/yearly_trend.png'

# 使用例
config = Config()

# app.py
app.run(debug=config.DEBUG, port=config.PORT)

# model_utils.py
df = pd.read_csv(file_path, encoding=config.CSV_ENCODING)
model = RandomForestRegressor(
    random_state=config.RANDOM_STATE,
    n_estimators=config.RF_N_ESTIMATORS,
    n_jobs=config.RF_N_JOBS
)
```

---

### 2.8 テストコードの不在（重要度：低）

#### 問題点
- 機能追加・修正時のリグレッション検証が困難
- コードの品質保証ができない
- リファクタリングのリスクが高い

#### 解決策：テストフレームワークの導入
```python
# tests/test_model_utils.py
import unittest
import pandas as pd
from model_utils import parse_distance, load_and_preprocess_data

class TestParseDistance(unittest.TestCase):
    def test_parse_minutes(self):
        self.assertEqual(parse_distance("5分"), 5)

    def test_parse_hours_minutes(self):
        self.assertEqual(parse_distance("1H30分"), 90)

    def test_parse_range(self):
        self.assertEqual(parse_distance("5～10分"), 7.5)

    def test_parse_numeric(self):
        self.assertEqual(parse_distance(10), 10)

class TestDataProcessing(unittest.TestCase):
    def setUp(self):
        # テスト用CSVを作成
        self.test_csv = "tests/fixtures/test_data.csv"

    def test_load_and_preprocess_data(self):
        df = load_and_preprocess_data(self.test_csv)
        self.assertIsInstance(df, pd.DataFrame)
        self.assertIn("取引価格（総額）", df.columns)

# tests/test_app.py
class TestFlaskRoutes(unittest.TestCase):
    def setUp(self):
        self.app = app.test_client()
        self.app.testing = True

    def test_upload_page_loads(self):
        response = self.app.get('/')
        self.assertEqual(response.status_code, 200)

    def test_upload_without_file(self):
        response = self.app.post('/')
        # エラーメッセージが表示されることを確認
```

---

### 2.9 ロギングの不足（重要度：低）

#### 問題点
- デバッグ時の情報が不足
- エラー発生時の原因特定が困難
- 運用時の監視ができない

#### 解決策
```python
import logging
from logging.handlers import RotatingFileHandler

# ロギング設定
def setup_logging(app):
    if not app.debug:
        # ファイルハンドラ
        file_handler = RotatingFileHandler(
            'logs/app.log',
            maxBytes=10240000,  # 10MB
            backupCount=10
        )
        file_handler.setFormatter(logging.Formatter(
            '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'
        ))
        file_handler.setLevel(logging.INFO)
        app.logger.addHandler(file_handler)

        app.logger.setLevel(logging.INFO)
        app.logger.info('Application startup')

# 使用例
@app.route("/", methods=["GET", "POST"])
def upload_file():
    if request.method == "POST":
        app.logger.info(f"File upload started: {file.filename}")
        try:
            # 処理
            app.logger.info("Prediction completed successfully")
        except Exception as e:
            app.logger.error(f"Prediction failed: {e}", exc_info=True)
```

---

### 2.10 型ヒントの不統一（重要度：低）

#### 問題箇所
```python
# 型ヒントあり
def process_and_predict(file_path: str, plot_path: str = "static/result.png"):

# 型ヒントなし
def parse_distance(distance):
def setup_japanese_font():
```

#### 問題点
- コードの可読性が低下
- IDEのサポートが不十分
- 型チェックツール（mypy）が使えない

#### 解決策
```python
from typing import Union, Dict, Tuple, Optional
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor

def setup_japanese_font() -> None:
    """クロスプラットフォーム対応の日本語フォント設定"""
    pass

def parse_distance(distance: Union[str, int, float]) -> Union[int, float]:
    """最寄駅距離を数値（分）に変換"""
    pass

def load_and_preprocess_data(file_path: str) -> pd.DataFrame:
    """CSVファイルを読み込み、前処理を行う"""
    pass

def create_features(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
    """特徴量を作成し、X, yを返す"""
    pass

def train_and_evaluate_model(
    X: pd.DataFrame,
    y: pd.Series
) -> Tuple[RandomForestRegressor, float, float, np.ndarray, np.ndarray]:
    """モデルを学習し、評価指標と予測値を返す"""
    pass

def aggregate_by_ward(
    df: pd.DataFrame,
    predictions: np.ndarray
) -> Tuple[Dict[str, int], Dict[str, int]]:
    """区ごとの予測・実価格を集計"""
    pass
```

---

## 3. リファクタリング優先順位

### 優先度1（即座に実施すべき）
1. ✅ **エラーハンドリングの追加** (app.py)
   - 影響: セキュリティ、ユーザビリティ
   - 工数: 2-3時間

2. ✅ **ファイルアップロードのセキュリティ対策** (app.py)
   - 影響: セキュリティ
   - 工数: 2-3時間

3. ✅ **グローバル変数の排除** (app.py)
   - 影響: スケーラビリティ、保守性
   - 工数: 3-4時間

### 優先度2（次のイテレーションで実施）
4. ✅ **process_and_predict関数の分割** (model_utils.py)
   - 影響: 保守性、テスタビリティ
   - 工数: 4-6時間

5. ✅ **設定ファイルの作成** (config.py)
   - 影響: 保守性、可搬性
   - 工数: 2-3時間

6. ✅ **データ重複読み込みの解消** (model_utils.py)
   - 影響: パフォーマンス
   - 工数: 1-2時間

### 優先度3（時間があれば実施）
7. ⭕ **テストコードの追加**
   - 影響: 品質保証
   - 工数: 6-8時間

8. ⭕ **ロギングの実装**
   - 影響: 運用性
   - 工数: 2-3時間

9. ⭕ **型ヒントの統一**
   - 影響: 可読性
   - 工数: 1-2時間

10. ⭕ **マジックナンバーの定数化**
    - 影響: 保守性
    - 工数: 1時間

---

## 4. リファクタリング後のディレクトリ構造案

```
newme/
├── app.py                    # Flaskアプリ（簡素化）
├── config.py                 # 設定ファイル（新規）
├── requirements.txt          # 依存パッケージ
├── README.md                 # 説明文書
│
├── models/                   # モデル関連（新規）
│   ├── __init__.py
│   ├── predictor.py          # 予測処理
│   ├── data_processor.py     # データ前処理
│   └── visualizer.py         # グラフ生成
│
├── utils/                    # ユーティリティ（新規）
│   ├── __init__.py
│   ├── file_handler.py       # ファイル処理
│   └── font_config.py        # フォント設定
│
├── services/                 # ビジネスロジック（新規）
│   ├── __init__.py
│   └── prediction_service.py # 予測サービス
│
├── templates/                # HTMLテンプレート
│   └── ...
│
├── static/                   # 静的ファイル
│   └── ...
│
├── input/                    # アップロードファイル
│   └── ...
│
├── logs/                     # ログファイル（新規）
│   └── app.log
│
└── tests/                    # テストコード（新規）
    ├── __init__.py
    ├── test_app.py
    ├── test_predictor.py
    ├── test_data_processor.py
    └── fixtures/
        └── test_data.csv
```

---

## 5. リファクタリング実施計画

### Phase 1: 緊急対応（1週間）
- [ ] エラーハンドリングの追加
- [ ] ファイルアップロードのセキュリティ対策
- [ ] グローバル変数の排除（Flaskセッション導入）

### Phase 2: コード品質改善（2週間）
- [ ] process_and_predict関数の分割
- [ ] 設定ファイルの作成
- [ ] データ重複読み込みの解消
- [ ] マジックナンバーの定数化

### Phase 3: 長期改善（3週間）
- [ ] テストコードの追加
- [ ] ロギングの実装
- [ ] 型ヒントの統一
- [ ] ドキュメントの整備

---

## 6. 期待される効果

### セキュリティ
- ファイルアップロード攻撃への耐性向上
- CSRF攻撃への対策
- DoS攻撃リスクの軽減

### 保守性
- コードの可読性向上（関数分割により1関数20-30行程度に）
- 変更容易性の向上（設定ファイル化により環境ごとの設定変更が容易）
- バグ修正時間の短縮（テストコードにより迅速な問題特定）

### パフォーマンス
- ファイル読み込み時間の短縮（重複排除）
- メモリ使用量の削減

### スケーラビリティ
- マルチユーザー対応（グローバル変数排除）
- 複数サーバーへのデプロイ可能性向上

---

## 7. リスクと対策

### リスク1: 既存機能の破壊
- **対策:** テストコードの先行作成、段階的なリファクタリング
- **検証:** 各Phase終了時に手動テスト実施

### リスク2: 開発時間の超過
- **対策:** Phase 1を最優先、Phase 3は時間があれば実施
- **検証:** 週次で進捗確認

### リスク3: 新たなバグの混入
- **対策:** コードレビューの徹底、ペアプログラミング
- **検証:** 自動テストの実行

---

## 8. 完了基準

### Phase 1
- [ ] 全てのエラーケースでユーザーにエラーメッセージが表示される
- [ ] ファイルアップロードで不正なファイルが拒否される
- [ ] グローバル変数が0個になる

### Phase 2
- [ ] process_and_predict関数が50行以下になる
- [ ] ハードコードされた設定値が0個になる
- [ ] CSVファイルの読み込みが1回のみになる

### Phase 3
- [ ] テストカバレッジが80%以上
- [ ] 全ての関数に型ヒントが付与される
- [ ] ログファイルが出力される

---

## 付録: 参考資料

- [Flask Best Practices](https://flask.palletsprojects.com/en/2.3.x/patterns/)
- [Python Code Style Guide (PEP 8)](https://pep8-ja.readthedocs.io/ja/latest/)
- [Clean Code in Python](https://github.com/zedr/clean-code-python)
- [Refactoring Guru](https://refactoring.guru/ja/refactoring)
